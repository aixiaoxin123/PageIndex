{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCh9BTedHJK1"
      },
      "source": [
        "![pageindex_banner](https://pageindex.ai/static/images/pageindex_banner.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nD0hb4TFHWTt"
      },
      "source": [
        "<p align=\"center\"><i>Reasoning-based RAG&nbsp; âœ§ &nbsp;No Vector DB&nbsp; âœ§ &nbsp;No Chunking&nbsp; âœ§ &nbsp;Human-like Retrieval</i></p>\n",
        "\n",
        "<p align=\"center\">\n",
        "  <a href=\"https://vectify.ai\">ğŸ  Homepage</a>&nbsp; â€¢ &nbsp;\n",
        "  <a href=\"https://dash.pageindex.ai\">ğŸ–¥ï¸ Dashboard</a>&nbsp; â€¢ &nbsp;\n",
        "  <a href=\"https://docs.pageindex.ai/quickstart\">ğŸ“š API Docs</a>&nbsp; â€¢ &nbsp;\n",
        "  <a href=\"https://github.com/VectifyAI/PageIndex\">ğŸ“¦ GitHub</a>&nbsp; â€¢ &nbsp;\n",
        "  <a href=\"https://discord.com/invite/VuXuf29EUj\">ğŸ’¬ Discord</a>&nbsp; â€¢ &nbsp;\n",
        "  <a href=\"https://ii2abc2jejf.typeform.com/to/tK3AXl8T\">âœ‰ï¸ Contact</a>&nbsp;\n",
        "</p>\n",
        "\n",
        "<div align=\"center\">\n",
        "\n",
        "[![Star us on GitHub](https://img.shields.io/github/stars/VectifyAI/PageIndex?style=for-the-badge&logo=github&label=â­ï¸%20Star%20Us)](https://github.com/VectifyAI/PageIndex) &nbsp;&nbsp; [![Follow us on X](https://img.shields.io/badge/Follow%20Us-000000?style=for-the-badge&logo=x&logoColor=white)](https://twitter.com/VectifyAI)\n",
        "\n",
        "</div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebvn5qfpcG1K"
      },
      "source": [
        "# Simple Vectorless RAG with PageIndex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PageIndex Introduction\n",
        "PageIndex is a new **reasoning-based**, **vectorless RAG** framework that performs retrieval in two steps:  \n",
        "1. Generate a tree structure index of documents  \n",
        "2. Perform reasoning-based retrieval through tree search  \n",
        "\n",
        "<div align=\"center\">\n",
        "  <img src=\"https://docs.pageindex.ai/images/cookbook/vectorless-rag.png\" width=\"70%\">\n",
        "</div>\n",
        "\n",
        "Compared to traditional vector-based RAG, PageIndex features:\n",
        "- **No Vectors Needed**: Uses document structure and LLM reasoning for retrieval.\n",
        "- **No Chunking Needed**: Documents are organized into natural sections rather than artificial chunks.\n",
        "- **Human-like Retrieval**: Simulates how human experts navigate and extract knowledge from complex documents. \n",
        "- **Transparent Retrieval Process**: Retrieval based on reasoning â€” say goodbye to approximate semantic search (\"vibe retrieval\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Notebook Overview\n",
        "\n",
        "This notebook demonstrates a simple, minimal example of **vectorless RAG** with PageIndex. You will learn how to:\n",
        "- [x] Build a PageIndex tree structure of a document\n",
        "- [x] Perform reasoning-based retrieval with tree search\n",
        "- [x] Generate answers based on the retrieved context\n",
        "\n",
        "> âš¡ Note: This is a **minimal example** to illustrate PageIndex's core philosophy and idea, not its full capabilities. More advanced examples are coming soon.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ziuTbbWcG1L"
      },
      "source": [
        "## Step 0: Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edTfrizMFK4c"
      },
      "source": [
        "#### 0.1 Install PageIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "LaoB58wQFNDh"
      },
      "outputs": [],
      "source": [
        "%pip install -q --upgrade pageindex"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVEWzPKGcG1M"
      },
      "source": [
        "#### 0.2 Setup PageIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StvqfcK4cG1M"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from pageindex.utils import (\n",
        "    print_toc, \n",
        "    remove_fields, \n",
        "    structure_to_list, \n",
        "    ChatGPT_API,\n",
        "    print_json\n",
        ")\n",
        "\n",
        "# é…ç½®æ¨¡å‹ (ä½¿ç”¨æœ¬åœ°/å…¼å®¹ OpenAI çš„ API)\n",
        "MODEL = \"qwen3-max\"\n",
        "\n",
        "# å°è£… LLM è°ƒç”¨ (åŒæ­¥ç‰ˆæœ¬)\n",
        "def call_llm(prompt, model=MODEL):\n",
        "    \"\"\"è°ƒç”¨ LLM ç”Ÿæˆå›å¤\"\"\"\n",
        "    return ChatGPT_API(model=model, prompt=prompt)\n",
        "\n",
        "# åˆ›å»ºèŠ‚ç‚¹æ˜ å°„çš„è¾…åŠ©å‡½æ•°\n",
        "def create_node_mapping(tree):\n",
        "    \"\"\"å°†æ ‘ç»“æ„è½¬æ¢ä¸º node_id -> node çš„å­—å…¸æ˜ å°„\"\"\"\n",
        "    node_list = structure_to_list(tree)\n",
        "    return {node['node_id']: node for node in node_list if 'node_id' in node}\n",
        "\n",
        "print(\"æœ¬åœ° RAG ç¯å¢ƒå·²é…ç½®å®Œæˆ\")\n",
        "print(f\"ä½¿ç”¨æ¨¡å‹: {MODEL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 0.3 é…ç½®ç¯å¢ƒå˜é‡\n",
        "\n",
        "ç¡®ä¿åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®äº†ä»¥ä¸‹ç¯å¢ƒå˜é‡:\n",
        "- `CHATGPT_API_KEY`: ä½ çš„ API Key\n",
        "- `BASE_URL`: API åŸºç¡€åœ°å€ (é»˜è®¤ä¸ºé˜¿é‡Œäº‘ DashScope)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# éªŒè¯ç¯å¢ƒå˜é‡é…ç½®\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "api_key = os.getenv(\"CHATGPT_API_KEY\")\n",
        "base_url = os.getenv(\"BASE_URL\", \"https://dashscope.aliyuncs.com/compatible-mode/v1\")\n",
        "\n",
        "if api_key:\n",
        "    print(f\"API Key å·²é…ç½® (å‰8ä½): {api_key[:8]}...\")\n",
        "    print(f\"Base URL: {base_url}\")\n",
        "else:\n",
        "    print(\"è­¦å‘Š: æœªæ‰¾åˆ° CHATGPT_API_KEY ç¯å¢ƒå˜é‡ï¼Œè¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heGtIMOVcG1N"
      },
      "source": [
        "## Step 1: PageIndex Tree Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzd1VWjwMUJL"
      },
      "source": [
        "#### 1.1 åŠ è½½æœ¬åœ°ç”Ÿæˆçš„ PageIndex æ ‘ç»“æ„\n",
        "\n",
        "ä½¿ç”¨æœ¬åœ°å·²ç”Ÿæˆçš„ç»“æ„æ–‡ä»¶ï¼Œè€Œéè°ƒç”¨äº‘ç«¯ APIã€‚\n",
        "\n",
        "> å¦‚éœ€ç”Ÿæˆæ–°çš„ç»“æ„æ–‡ä»¶ï¼Œè¯·ä½¿ç”¨ `run_pageindex_md.py` æˆ– `page_index.py` è„šæœ¬ã€‚"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6--eZPLcG1N",
        "outputId": "ca688cfd-6c4b-4a57-dac2-f3c2604c4112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded https://arxiv.org/pdf/2501.12948.pdf\n",
            "Document Submitted: pi-cmeseq08w00vt0bo3u6tr244g\n"
          ]
        }
      ],
      "source": [
        "# åŠ è½½æœ¬åœ°ç”Ÿæˆçš„ç»“æ„æ–‡ä»¶\n",
        "# ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„ç»“æ„æ–‡ä»¶è·¯å¾„\n",
        "STRUCTURE_PATH = r\"D:\\github_dir\\pageindex_project\\results\\æ±‡æ€»æ–‡æ¡£v1_structure.json\"\n",
        "\n",
        "# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
        "if not os.path.exists(STRUCTURE_PATH):\n",
        "    print(f\"é”™è¯¯: ç»“æ„æ–‡ä»¶ä¸å­˜åœ¨: {STRUCTURE_PATH}\")\n",
        "    print(\"è¯·å…ˆä½¿ç”¨ PageIndex ç”Ÿæˆæ–‡æ¡£ç»“æ„\")\n",
        "else:\n",
        "    with open(STRUCTURE_PATH, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    tree = data['structure']\n",
        "    print(f\"æˆåŠŸåŠ è½½ç»“æ„æ–‡ä»¶: {STRUCTURE_PATH}\")\n",
        "    print(f\"æ–‡æ¡£æ ‡é¢˜: {tree.get('title', 'æœªçŸ¥')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Hrh0azcG1N"
      },
      "source": [
        "#### 1.2 æŸ¥çœ‹æ–‡æ¡£æ ‘ç»“æ„"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "b1Q1g6vrcG1O",
        "outputId": "dc944660-38ad-47ea-d358-be422edbae53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simplified Tree Structure of the Document:\n",
            "[{'title': 'DeepSeek-R1: Incentivizing Reasoning Cap...',\n",
            "  'node_id': '0000',\n",
            "  'prefix_summary': '# DeepSeek-R1: Incentivizing Reasoning C...',\n",
            "  'nodes': [{'title': 'Abstract',\n",
            "             'node_id': '0001',\n",
            "             'summary': 'The partial document introduces two reas...'},\n",
            "            {'title': 'Contents',\n",
            "             'node_id': '0002',\n",
            "             'summary': 'This partial document provides a detaile...'},\n",
            "            {'title': '1. Introduction',\n",
            "             'node_id': '0003',\n",
            "             'prefix_summary': 'The partial document introduces recent a...',\n",
            "             'nodes': [{'title': '1.1. Contributions',\n",
            "                        'node_id': '0004',\n",
            "                        'summary': 'This partial document outlines the main ...'},\n",
            "                       {'title': '1.2. Summary of Evaluation Results',\n",
            "                        'node_id': '0005',\n",
            "                        'summary': 'The partial document provides a summary ...'}]},\n",
            "            {'title': '2. Approach',\n",
            "             'node_id': '0006',\n",
            "             'prefix_summary': '## 2. Approach\\n',\n",
            "             'nodes': [{'title': '2.1. Overview',\n",
            "                        'node_id': '0007',\n",
            "                        'summary': '### 2.1. Overview\\n\\nPrevious work has hea...'},\n",
            "                       {'title': '2.2. DeepSeek-R1-Zero: Reinforcement Lea...',\n",
            "                        'node_id': '0008',\n",
            "                        'prefix_summary': '### 2.2. DeepSeek-R1-Zero: Reinforcement...',\n",
            "                        'nodes': [{'title': '2.2.1. Reinforcement Learning Algorithm',\n",
            "                                   'node_id': '0009',\n",
            "                                   'summary': 'The partial document describes the Group...'},\n",
            "                                  {'title': '2.2.2. Reward Modeling',\n",
            "                                   'node_id': '0010',\n",
            "                                   'summary': 'This partial document discusses the rewa...'},\n",
            "                                  {'title': '2.2.3. Training Template',\n",
            "                                   'node_id': '0011',\n",
            "                                   'summary': '#### 2.2.3. Training Template\\n\\nTo train ...'},\n",
            "                                  {'title': '2.2.4. Performance, Self-evolution Proce...',\n",
            "                                   'node_id': '0012',\n",
            "                                   'summary': 'This partial document discusses the perf...'}]},\n",
            "                       {'title': '2.3. DeepSeek-R1: Reinforcement Learning...',\n",
            "                        'node_id': '0013',\n",
            "                        'summary': 'This partial document describes the trai...'},\n",
            "                       {'title': '2.4. Distillation: Empower Small Models ...',\n",
            "                        'node_id': '0014',\n",
            "                        'summary': 'This partial document discusses the proc...'}]},\n",
            "            {'title': '3. Experiment',\n",
            "             'node_id': '0015',\n",
            "             'prefix_summary': 'The partial document describes the exper...',\n",
            "             'nodes': [{'title': '3.1. DeepSeek-R1 Evaluation',\n",
            "                        'node_id': '0016',\n",
            "                        'summary': 'This partial document presents a compreh...'},\n",
            "                       {'title': '3.2. Distilled Model Evaluation',\n",
            "                        'node_id': '0017',\n",
            "                        'summary': 'This partial document presents an evalua...'}]},\n",
            "            {'title': '4. Discussion',\n",
            "             'node_id': '0018',\n",
            "             'summary': 'This partial document discusses the comp...'},\n",
            "            {'title': '5. Conclusion, Limitations, and Future W...',\n",
            "             'node_id': '0019',\n",
            "             'summary': 'This partial document presents the concl...'},\n",
            "            {'title': 'References',\n",
            "             'node_id': '0020',\n",
            "             'summary': 'This partial document consists of the re...'},\n",
            "            {'title': 'Appendix', 'node_id': '0021', 'summary': '## Appendix\\n'},\n",
            "            {'title': 'A. Contributions and Acknowledgments',\n",
            "             'node_id': '0022',\n",
            "             'summary': 'This partial document section details th...'}]}]\n"
          ]
        }
      ],
      "source": [
        "# æ‰“å°æ–‡æ¡£ç›®å½•ç»“æ„\n",
        "print(\"=== æ–‡æ¡£ç›®å½•ç»“æ„ ===\")\n",
        "if isinstance(tree, dict):\n",
        "    print_toc([tree])\n",
        "elif isinstance(tree, list):\n",
        "    print_toc(tree)\n",
        "\n",
        "# åˆ›å»ºèŠ‚ç‚¹æ˜ å°„\n",
        "node_map = create_node_mapping(tree)\n",
        "print(f\"\\n=== å…± {len(node_map)} ä¸ªèŠ‚ç‚¹ ===\")\n",
        "for node_id, node in node_map.items():\n",
        "    summary = node.get('summary', 'æ— æ‘˜è¦')\n",
        "    summary_preview = summary[:60] + '...' if len(summary) > 60 else summary\n",
        "    print(f\"  {node_id}: {node['title']} - {summary_preview}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USoCLOiQcG1O"
      },
      "source": [
        "## Step 2: Reasoning-Based Retrieval with Tree Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.1 è®¾ç½®æŸ¥è¯¢é—®é¢˜"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLHNJAtTcG1O"
      },
      "outputs": [],
      "source": [
        "# è®¾ç½®æŸ¥è¯¢é—®é¢˜\n",
        "query = \"è¿™ä»½æ–‡æ¡£çš„ä¸»è¦å†…å®¹æ˜¯ä»€ä¹ˆï¼Ÿ\"\n",
        "print(f\"æŸ¥è¯¢é—®é¢˜: {query}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2.2 ä½¿ç”¨ LLM è¿›è¡Œæ ‘æœç´¢ï¼Œæ‰¾å‡ºç›¸å…³èŠ‚ç‚¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "P8DVUOuAen5u",
        "outputId": "6bb6d052-ef30-4716-f88e-be98bcb7ebdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reasoning Process:\n",
            "The question asks for the conclusions in the document. Typically, conclusions are found in sections\n",
            "explicitly titled 'Conclusion' or in sections summarizing the findings and implications of the work.\n",
            "In this document tree, node 0019 ('5. Conclusion, Limitations, and Future Work') is the most\n",
            "directly relevant, as it is dedicated to the conclusion and related topics. Additionally, the\n",
            "'Abstract' (node 0001) may contain a high-level summary that sometimes includes concluding remarks,\n",
            "but it is less likely to contain the full conclusions. Other sections like 'Discussion' (node 0018)\n",
            "may discuss implications but are not explicitly conclusions. Therefore, the primary node is 0019.\n",
            "\n",
            "Retrieved Nodes:\n",
            "Node ID: 0019\t Page: 16\t Title: 5. Conclusion, Limitations, and Future Work\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "# å¯¹äºåªæœ‰ä¸€ä¸ªèŠ‚ç‚¹çš„ç®€å•æ–‡æ¡£ï¼Œç›´æ¥ä½¿ç”¨è¯¥èŠ‚ç‚¹\n",
        "if len(node_map) == 1:\n",
        "    selected_node_ids = list(node_map.keys())\n",
        "    print(f\"æ–‡æ¡£åªæœ‰ä¸€ä¸ªèŠ‚ç‚¹ï¼Œç›´æ¥ä½¿ç”¨: {selected_node_ids[0]}\")\n",
        "else:\n",
        "    # å¤šèŠ‚ç‚¹æ—¶ä½¿ç”¨ LLM æœç´¢\n",
        "    # æ„å»ºèŠ‚ç‚¹æ‘˜è¦ä¿¡æ¯ä¾› LLM é€‰æ‹©\n",
        "    node_summaries = []\n",
        "    for node_id, node in node_map.items():\n",
        "        summary = node.get('summary', node.get('title', 'æ— æ‘˜è¦'))\n",
        "        node_summaries.append(f\"- {node_id}: {node['title']} - {summary[:200]}\")\n",
        "    \n",
        "    search_prompt = f\"\"\"ä½ æ˜¯ä¸€ä¸ªæ–‡æ¡£æ£€ç´¢åŠ©æ‰‹ã€‚æ ¹æ®é—®é¢˜ï¼Œä»ä»¥ä¸‹èŠ‚ç‚¹ä¸­æ‰¾å‡ºæœ€å¯èƒ½åŒ…å«ç­”æ¡ˆçš„èŠ‚ç‚¹ã€‚\n",
        "\n",
        "é—®é¢˜: {query}\n",
        "\n",
        "å¯ç”¨èŠ‚ç‚¹:\n",
        "{chr(10).join(node_summaries)}\n",
        "\n",
        "è¯·åªè¿”å›ä¸€ä¸ª JSON æ•°ç»„ï¼ŒåŒ…å«æœ€ç›¸å…³çš„ node_idï¼ˆæœ€å¤š3ä¸ªï¼‰ï¼Œæ ¼å¼å¦‚: [\"0001\", \"0003\"]\n",
        "ä¸è¦è¿”å›å…¶ä»–å†…å®¹ã€‚\n",
        "\"\"\"\n",
        "    \n",
        "    print(\"æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œæ ‘æœç´¢...\")\n",
        "    node_ids_response = call_llm(search_prompt)\n",
        "    print(f\"LLM è¿”å›: {node_ids_response}\")\n",
        "    \n",
        "    # è§£æ LLM è¿”å›çš„èŠ‚ç‚¹ ID\n",
        "    try:\n",
        "        match = re.search(r'\\[.*?\\]', node_ids_response, re.DOTALL)\n",
        "        if match:\n",
        "            parsed_ids = json.loads(match.group())\n",
        "            # è¿‡æ»¤å‡ºæœ‰æ•ˆçš„èŠ‚ç‚¹ ID\n",
        "            selected_node_ids = [nid for nid in parsed_ids if nid in node_map]\n",
        "            if not selected_node_ids:\n",
        "                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆèŠ‚ç‚¹ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªéæ ¹èŠ‚ç‚¹\n",
        "                selected_node_ids = [list(node_map.keys())[1] if len(node_map) > 1 else list(node_map.keys())[0]]\n",
        "                print(f\"LLM è¿”å›çš„èŠ‚ç‚¹æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤èŠ‚ç‚¹: {selected_node_ids}\")\n",
        "        else:\n",
        "            selected_node_ids = [list(node_map.keys())[1] if len(node_map) > 1 else list(node_map.keys())[0]]\n",
        "            print(f\"æ— æ³•è§£æ LLM è¿”å›ï¼Œä½¿ç”¨é»˜è®¤èŠ‚ç‚¹: {selected_node_ids}\")\n",
        "    except Exception as e:\n",
        "        print(f\"è§£æé”™è¯¯: {e}\")\n",
        "        selected_node_ids = [list(node_map.keys())[1] if len(node_map) > 1 else list(node_map.keys())[0]]\n",
        "\n",
        "print(f\"\\né€‰ä¸­çš„èŠ‚ç‚¹: {selected_node_ids}\")\n",
        "for nid in selected_node_ids:\n",
        "    print(f\"  - {nid}: {node_map[nid]['title']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10wOZDG_cG1O"
      },
      "source": [
        "## Step 3: Answer Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1 æå–ç›¸å…³èŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡å†…å®¹"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "a7UCBnXlcG1O",
        "outputId": "8a026ea3-4ef3-473a-a57b-b4565409749e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Retrieved Context:\n",
            "\n",
            "## 5. Conclusion, Limitations, and Future Work\n",
            "\n",
            "In this work, we share our journey in enhancing model reasoning abilities through reinforcement\n",
            "learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start data,\n",
            "achieving strong performance across various tasks. DeepSeek-R1 is more powerful, leveraging cold-\n",
            "start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 achieves performance\n",
            "comparable to OpenAI-o1-1217 on a range of tasks.\n",
            "\n",
            "We further explore distillation the reasoning capability to small dense models. We use DeepSeek-R1\n",
            "as the teacher model to generate 800K training samples, and fine-tune several small dense models.\n",
            "The results are promising: DeepSeek-R1-Distill-Qwen-1.5B outperforms GPT-4o and Claude-3.5-Sonnet on\n",
            "math benchmarks with $28.9 \\%$ on AIME and $83.9 \\%$ on MATH. Other dense models also achieve\n",
            "impressive results, significantly outperforming other instructiontuned models based on the same\n",
            "underlying checkpoints.\n",
            "\n",
            "In the fut...\n"
          ]
        }
      ],
      "source": [
        "# æ”¶é›†æ‰€æœ‰é€‰ä¸­èŠ‚ç‚¹çš„å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡\n",
        "context_parts = []\n",
        "for nid in selected_node_ids:\n",
        "    node = node_map[nid]\n",
        "    if 'text' in node and node['text']:\n",
        "        context_parts.append(f\"ã€{node['title']}ã€‘\\n{node['text']}\")\n",
        "    elif 'summary' in node:\n",
        "        context_parts.append(f\"ã€{node['title']}ã€‘\\n{node['summary']}\")\n",
        "    else:\n",
        "        context_parts.append(f\"ã€{node['title']}ã€‘\\n(æ— å†…å®¹)\")\n",
        "\n",
        "if context_parts:\n",
        "    context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
        "else:\n",
        "    context = \"æœªæ‰¾åˆ°ç›¸å…³å†…å®¹\"\n",
        "\n",
        "# æ˜¾ç¤ºä¸Šä¸‹æ–‡é¢„è§ˆ\n",
        "print(f\"=== æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ (å‰800å­—) ===\\n\")\n",
        "print(context[:800])\n",
        "if len(context) > 800:\n",
        "    print(f\"\\n... (å…± {len(context)} å­—)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.2 åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "tcp_PhHzcG1O",
        "outputId": "187ff116-9bb0-4ab4-bacb-13944460b5ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated Answer:\n",
            "\n",
            "The conclusions in this document are:\n",
            "\n",
            "- DeepSeek-R1-Zero, a pure reinforcement learning (RL) approach without cold-start data, achieves\n",
            "strong performance across various tasks.\n",
            "- DeepSeek-R1, which combines cold-start data with iterative RL fine-tuning, is more powerful and\n",
            "achieves performance comparable to OpenAI-o1-1217 on a range of tasks.\n",
            "- Distilling DeepSeek-R1â€™s reasoning capabilities into smaller dense models is promising; for\n",
            "example, DeepSeek-R1-Distill-Qwen-1.5B outperforms GPT-4o and Claude-3.5-Sonnet on math benchmarks,\n",
            "and other dense models also show significant improvements over similar instruction-tuned models.\n",
            "\n",
            "These results demonstrate the effectiveness of the RL-based approach and the potential for\n",
            "distilling reasoning abilities into smaller models.\n"
          ]
        }
      ],
      "source": [
        "# æ„å»ºç­”æ¡ˆç”Ÿæˆçš„æç¤ºè¯\n",
        "answer_prompt = f\"\"\"æ ¹æ®ä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ã€‚\n",
        "\n",
        "é—®é¢˜: {query}\n",
        "\n",
        "ä¸Šä¸‹æ–‡: \n",
        "{context}\n",
        "\n",
        "è¯·åŸºäºä¸Šä¸‹æ–‡å†…å®¹ï¼Œç»™å‡ºæ¸…æ™°ã€å‡†ç¡®çš„å›ç­”ã€‚å¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´æ˜ã€‚\n",
        "\"\"\"\n",
        "\n",
        "print(\"=== æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ... ===\\n\")\n",
        "answer = call_llm(answer_prompt)\n",
        "\n",
        "print(\"=== ç”Ÿæˆçš„ç­”æ¡ˆ ===\\n\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1kaGD3GcG1O"
      },
      "source": [
        "---\n",
        "\n",
        "## å®Œæ•´æµç¨‹æ€»ç»“\n",
        "\n",
        "æœ¬ notebook æ¼”ç¤ºäº† **æœ¬åœ°åŒ–çš„æ— å‘é‡ RAG** å·¥ä½œæµç¨‹:\n",
        "\n",
        "1. **åŠ è½½æœ¬åœ°ç»“æ„æ–‡ä»¶**: ä½¿ç”¨ PageIndex é¢„å…ˆç”Ÿæˆçš„æ–‡æ¡£æ ‘ç»“æ„ (JSON æ ¼å¼)\n",
        "2. **æ ‘æœç´¢æ£€ç´¢**: é€šè¿‡ LLM æ¨ç†ï¼Œæ ¹æ®èŠ‚ç‚¹æ‘˜è¦æ‰¾å‡ºä¸é—®é¢˜ç›¸å…³çš„èŠ‚ç‚¹\n",
        "3. **ä¸Šä¸‹æ–‡æå–**: ä»é€‰ä¸­èŠ‚ç‚¹ä¸­æå–æ–‡æœ¬å†…å®¹ä½œä¸ºä¸Šä¸‹æ–‡\n",
        "4. **ç­”æ¡ˆç”Ÿæˆ**: åŸºäºæ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ\n",
        "\n",
        "### ä¸äº‘ç«¯ API ç‰ˆæœ¬çš„åŒºåˆ«\n",
        "\n",
        "| ç‰¹æ€§ | äº‘ç«¯ API ç‰ˆæœ¬ | æœ¬åœ°ç‰ˆæœ¬ |\n",
        "|------|--------------|---------|\n",
        "| ç»“æ„ç”Ÿæˆ | è°ƒç”¨ PageIndex API | ä½¿ç”¨æœ¬åœ° `page_index.py` ç”Ÿæˆ |\n",
        "| æ•°æ®å­˜å‚¨ | äº‘ç«¯æ‰˜ç®¡ | æœ¬åœ° JSON æ–‡ä»¶ |\n",
        "| LLM è°ƒç”¨ | OpenAI API | å…¼å®¹ OpenAI çš„ä»»æ„ API (å¦‚é˜¿é‡Œäº‘ DashScope) |\n",
        "| éšç§æ€§ | æ•°æ®ä¸Šä¼ äº‘ç«¯ | æ•°æ®å®Œå…¨æœ¬åœ°åŒ– |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ä¸‹ä¸€æ­¥\n",
        "\n",
        "- ä¿®æ”¹ `STRUCTURE_PATH` ä½¿ç”¨ä½ è‡ªå·±çš„æ–‡æ¡£ç»“æ„æ–‡ä»¶\n",
        "- ä¿®æ”¹ `query` æµ‹è¯•ä¸åŒçš„é—®é¢˜\n",
        "- è°ƒæ•´ `MODEL` ä½¿ç”¨ä¸åŒçš„ LLM æ¨¡å‹\n",
        "\n",
        "---\n",
        "\n",
        "Â© 2025 PageIndex æœ¬åœ°åŒ– RAG ç¤ºä¾‹"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
